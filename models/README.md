# Modelli LLM

Per usare questo progetto Ã¨ necessario scaricare manualmente i seguenti modelli `.gguf`:

- [Mistral-7B-Instruct-v0.1.Q4_K_M.gguf](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF)
  - Dimensione: ~4.2 GB
  - Quantizzazione: Q4_K_M
  - Posiziona il file in `models/`

Assicurati di scaricare la versione GGUF compatibile con `llama-cpp-python`.
